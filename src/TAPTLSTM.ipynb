{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f020388-58f0-4da9-933a-6a02129cd624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3553cab790e4421185f9f691418900d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Basins:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import jax\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Force reload of project files\n",
    "import data, train, models, evaluate, metrics\n",
    "importlib.reload(data)\n",
    "from data import TAPDataset\n",
    "\n",
    "data_dir = Path(\"../data/wqp\")\n",
    "basin_list_file = data_dir / \"metadata\" / \"site_lists\" / \"sites_all.txt\"\n",
    "# basin_list_file = data_dir / \"metadata\" / \"site_lists\" / \"sites_ssc_area1000_n10.txt\"\n",
    "\n",
    "with open(basin_list_file, 'r') as file:\n",
    "    basin_list = file.readlines()\n",
    "    basin_list = [basin.strip() for basin in basin_list]\n",
    "\n",
    "basin_list = basin_list[:10]\n",
    "\n",
    "data_params = {'data_dir': data_dir,\n",
    "               'basin_list': basin_list,\n",
    "               'features_dict': {'daily':['grfr_q'],\n",
    "                                 'irregular':['Blue','Green','Red','Nir','Swir1','Swir2']},\n",
    "               'target': 'turbidity',\n",
    "               'time_slice': slice('1979-01-01', '2018-12-31'),\n",
    "               'split_time': np.datetime64('2010-01-01'),\n",
    "               'sequence_length': 7,\n",
    "               'log_norm_cols': ['turbidity', 'grfr_q'],\n",
    "               'clip_target_to_zero': True,\n",
    "               'discharge_col': 'grfr_q'}\n",
    "\n",
    "dataset = TAPDataset(**data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf7426d-3964-4d94-9fc4-f1ebbc279a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader using 1 parallel CPU worker(s).\n",
      "Batch sharding set to 1 cpu(s)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(data)\n",
    "from data import TAPDataset, TAPDataLoader\n",
    "\n",
    "loader_params = {'suffle': True,\n",
    "                 'batch_size': 3,\n",
    "                 'num_workers': 1,\n",
    "                 'pin_memory': True} \n",
    "dataloader = TAPDataLoader(dataset, **loader_params)\n",
    "# dataloader.set_mode(train=True, sequence=True, end2end=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc59deca-8b6c-4756-a2e2-f9dcaaae1697",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'data.TAPDataset'>: it's not the same object as data.TAPDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tssml-WvnpDPLB-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:434\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_workers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\u001b[38;5;241m.\u001b[39m_reset(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tssml-WvnpDPLB-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tssml-WvnpDPLB-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:289\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'data.TAPDataset'>: it's not the same object as data.TAPDataset"
     ]
    }
   ],
   "source": [
    "for _, _, batch in dataloader:\n",
    "    break\n",
    "batch['y'][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9e66e-0054-4dab-8dc5-0c6434c17fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data)\n",
    "importlib.reload(models)\n",
    "importlib.reload(train)\n",
    "from data import TAPDataLoader\n",
    "from models import TAPLSTM, EALSTM, LSTM\n",
    "from train import Trainer\n",
    "\n",
    "\n",
    "daily_in_size = len(data_params['features_dict']['daily'])\n",
    "irregular_in_size = len(data_params['features_dict']['irregular'])\n",
    "static_in_size = dataset.x_s[basin_list[0]].shape[0]\n",
    "output_size = 1\n",
    "\n",
    "hidden_size = 16\n",
    "dropout = 0.4\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "model = TAPLSTM(daily_in_size, irregular_in_size, static_in_size, output_size, hidden_size, key=key, dropout=dropout)\n",
    "# model = LSTM(daily_in_size, output_size, hidden_size, key=key, dropout=dropout)\n",
    "# model = EALSTM(daily_in_size, static_in_size, output_size, hidden_size, key=key, dropout=dropout)\n",
    "\n",
    "loader_params = {'suffle': True,\n",
    "                 'batch_size': 3,\n",
    "                 'train':True,\n",
    "                 'sequence':True,\n",
    "                 'end2end': True,\n",
    "                 'num_workers': 1,\n",
    "                 'pin_memory': True} \n",
    "dataloader = TAPDataLoader(dataset, **loader_params)\n",
    "\n",
    "num_epochs =  15\n",
    "# lr_schedule = optax.polynomial_schedule(0.01, 0.0001, 2, num_epochs)\n",
    "lr_schedule = optax.exponential_decay(0.005, num_epochs, 0.5)\n",
    "trainer = Trainer(model, dataloader, lr_schedule, num_epochs, max_grad_norm=2)\n",
    "model = trainer.start_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927cc8a-a06b-4251-b789-2929389f1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.num_epochs=1000\n",
    "model = trainer.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547baa72-8eb7-43a1-93a2-a69369488cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c6985-2614-4dbb-8cc5-477912e1b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ca8c8-9369-4020-8b90-a935d979b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import get_all_metrics\n",
    "\n",
    "importlib.reload(evaluate)\n",
    "from evaluate import predict\n",
    "\n",
    "#Need a sr evaluate mode. Maybe just rethink the entire indexing scheme.\n",
    "dataloader = TAPDataLoader(dataset, **loader_params)\n",
    "basin = np.random.choice(basin_list).tolist()\n",
    "dataloader.set_mode(train=False, sequence=True, end2end=True, basin_subset=basin)\n",
    "results = predict(model, dataloader, denormalize=True)\n",
    "results['pred'] = results['pred'] * (results['pred']>0) #Clip predictions to 0\n",
    "metrics = get_all_metrics(results['obs'],results['pred'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35e0e8-6279-4f8b-9559-24f543f7bda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e119cc9-dc63-411f-a3a8-0a17c5865b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the true values and predictions\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "basin_results['pred'].plot(ax=ax)\n",
    "basin_results['obs'].plot(ax=ax,linestyle='None',marker='.')\n",
    "\n",
    "metrics = get_all_metrics(basin_results['obs'],basin_results['pred'])\n",
    "\n",
    "plt.title(f\"Basin: {basin_subset}, KGE: {metrics['kge']:0.4f}\")\n",
    "plt.legend()\n",
    "plt.ylim([0,500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fec15c-904c-4b45-b531-f36c771772c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.scatter('obs','pred')\n",
    "plt.gca().axis('square')\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0,20])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
