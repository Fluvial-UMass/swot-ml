{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c2f660-7607-4db7-975e-791971031c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is required to run multiple processes on Unity for some reason.\n",
    "from multiprocessing import set_start_method\n",
    "set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f020388-58f0-4da9-933a-6a02129cd624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30674e905364b618622e7822ea5f9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Basins:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import jax\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Force reload of project files\n",
    "import data, train, models, evaluate, metrics\n",
    "importlib.reload(data)\n",
    "from data import TAPDataset, TAPDataLoader\n",
    "\n",
    "data_dir = Path(\"../data/wqp\")\n",
    "# basin_list_file = data_dir / \"metadata\" / \"site_lists\" / \"sites_all.txt\"\n",
    "basin_list_file = data_dir / \"metadata\" / \"site_lists\" / \"sites_turb_area1000_n10.txt\"\n",
    "\n",
    "with open(basin_list_file, 'r') as file:\n",
    "    basin_list = file.readlines()\n",
    "    basin_list = [basin.strip() for basin in basin_list]\n",
    "\n",
    "basin_list = np.random.choice(basin_list,10)\n",
    "\n",
    "data_args = {'data_dir': data_dir,\n",
    "             'basin_list': basin_list,\n",
    "             'features_dict': {'daily':['grfr_q'],\n",
    "                               'irregular':['Blue','Green','Red','Nir','Swir1','Swir2']},\n",
    "             'static_features':['wet_pc_s02', 'glc_pc_s11', 'dor_pc_pva', 'soc_th_sav', 'snw_pc_s08', \n",
    "                                'wet_pc_s09', 'fmh_cl_smj', 'glc_pc_s14', 'pnv_pc_s11', 'pac_pc_sse'],\n",
    "             'target': 'turbidity',\n",
    "             'time_slice': slice('1979-01-01', '2018-12-31'),\n",
    "             'split_time': np.datetime64('2010-01-01'),\n",
    "             'sequence_length': 30,\n",
    "             'log_norm_cols': ['turbidity', 'grfr_q'],\n",
    "             'clip_target_to_zero': True}\n",
    "\n",
    "dataset = TAPDataset(**data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd9e66e-0054-4dab-8dc5-0c6434c17fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader using 1 parallel CPU worker(s).\n",
      "Batch sharding set to 1 gpu(s)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "EALSTM.__init__() missing 1 required keyword-only argument: 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     30\u001b[0m lr_schedule \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mexponential_decay(\u001b[38;5;241m0.01\u001b[39m, num_epochs, \u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     31\u001b[0m trainer_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_func\u001b[39m\u001b[38;5;124m'\u001b[39m: EALSTM,\n\u001b[1;32m     32\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_args\u001b[39m\u001b[38;5;124m'\u001b[39m: model_args,\n\u001b[1;32m     33\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m'\u001b[39m: dataloader,\n\u001b[1;32m     34\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m: lr_schedule,\n\u001b[1;32m     35\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: num_epochs,\n\u001b[1;32m     36\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_grad_norm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m---> 38\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstart_training()\n",
      "File \u001b[0;32m/work/pi_kandread_umass_edu/tss-ml/src/train.py:49\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model_func, model_args, dataloader, lr_schedule, num_epochs, model, log_interval, **step_kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_kwargs \u001b[38;5;241m=\u001b[39m step_kwargs\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/.conda/envs/tss-ml/lib/python3.10/site-packages/equinox/_module.py:514\u001b[0m, in \u001b[0;36m_ModuleMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m initable_cls \u001b[38;5;241m=\u001b[39m _make_initable(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, post_init, wraps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# [Step 2] Instantiate the class as normal.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_ModuleMeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitable_cls\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_abstract(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# [Step 3] Check that all fields are occupied.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/tss-ml/lib/python3.10/site-packages/equinox/_module.py:346\u001b[0m, in \u001b[0;36m_ModuleMeta.__new__.<locals>.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;129m@ft\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(init)  \u001b[38;5;66;03m# pyright: ignore\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    345\u001b[0m     __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m     \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;66;03m# Same `if` trick as with `__post_init__`.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: EALSTM.__init__() missing 1 required keyword-only argument: 'key'"
     ]
    }
   ],
   "source": [
    "importlib.reload(models)\n",
    "importlib.reload(train)\n",
    "from models import TAPLSTM, EALSTM, LSTM\n",
    "from train import Trainer\n",
    "\n",
    "loader_args = {'shuffle': True,\n",
    "               'batch_size': 16,\n",
    "               'data_subset': 'pre-train',\n",
    "               'num_workers': 1,\n",
    "               'pin_memory': True} \n",
    "dataloader = TAPDataLoader(dataset, **loader_args)\n",
    "\n",
    "\n",
    "# model_args = {'daily_in_size': len(data_args['features_dict']['daily']),\n",
    "#               'irregular_in_size': len(data_args['features_dict']['irregular']),\n",
    "#               'static_in_size': dataset.x_s[basin_list[0]].shape[0],\n",
    "#               'out_size': 1,\n",
    "#               'hidden_size': 16,\n",
    "#               'dropout': 0.4,\n",
    "#               'seed': 0}\n",
    "\n",
    "model_args = {'dynamic_in_size': len(data_args['features_dict']['daily']),\n",
    "              'static_in_size': dataset.x_s[basin_list[0]].shape[0],\n",
    "              'out_size': 1,\n",
    "              'hidden_size': 16,\n",
    "              'dropout': 0.4,\n",
    "              'seed': 0}\n",
    "\n",
    "num_epochs = 250\n",
    "lr_schedule = optax.exponential_decay(0.01, num_epochs, 0.01)\n",
    "trainer_args = {'model_func': EALSTM,\n",
    "                'model_args': model_args,\n",
    "                'dataloader': dataloader,\n",
    "                'lr_schedule': lr_schedule,\n",
    "                'num_epochs': num_epochs,\n",
    "                'max_grad_norm': 2}\n",
    "\n",
    "trainer = Trainer(**trainer_args)\n",
    "trainer.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe339df-1e23-4067-9107-a774c6884a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_epochs = 150\n",
    "\n",
    "trainer.load_state('epoch100')\n",
    "loader_args['data_subset'] = 'train'\n",
    "trainer.dataloader = TAPDataLoader(dataset, **loader_args)\n",
    "trainer.lr_schedule = optax.exponential_decay(0.01, trainer.epoch+more_epochs, 0.001, transition_begin=trainer.epoch)\n",
    "trainer.num_epochs += more_epochs\n",
    "trainer.freeze_components('tealstm_i',True)\n",
    "trainer.start_training() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0777957-11f3-49db-b4a4-67d729527ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = optax.exponential_decay(0.01, trainer.epoch+num_epochs, 0.001, transition_begin=trainer.epoch)\n",
    "x = np.linspace(0,num_epochs*2)\n",
    "y = lr_schedule(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ca8c8-9369-4020-8b90-a935d979b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import get_all_metrics\n",
    "\n",
    "importlib.reload(evaluate)\n",
    "from evaluate import predict\n",
    "\n",
    "basin = np.random.choice(basin_list).tolist()\n",
    "\n",
    "loader_args['data_subset'] = 'test'\n",
    "loader_args['basin_subset'] =  basin\n",
    "loader_args['num_workers'] = 0 # Faster for small runs\n",
    "dataloader = TAPDataLoader(dataset, **loader_args)\n",
    "\n",
    "results = predict(trainer.model, dataloader, denormalize=True)\n",
    "results['pred'] = results['pred'] * (results['pred']>0) #Clip predictions to 0\n",
    "metrics = get_all_metrics(results['obs'],results['pred'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35e0e8-6279-4f8b-9559-24f543f7bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e119cc9-dc63-411f-a3a8-0a17c5865b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the true values and predictions\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "results['pred'].plot(ax=ax)\n",
    "results['obs'].plot(ax=ax,linestyle='None',marker='.')\n",
    "\n",
    "metrics = get_all_metrics(results['obs'],results['pred'])\n",
    "\n",
    "plt.title(f\"Basin: {basin}, KGE: {metrics['kge']:0.4f}\")\n",
    "plt.legend()\n",
    "plt.ylim([0,500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fec15c-904c-4b45-b531-f36c771772c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.scatter('obs','pred')\n",
    "plt.gca().axis('square')\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dcf4b4-1d1b-49e1-af29-91faeb56590e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d973e14-3b94-4f55-b971-e7aebf7887e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe46d7-39ac-421b-94bd-cf015c31e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import make_step\n",
    "\n",
    "# See if we can recreate the error... \n",
    "data = trainer.load_state(\"exceptions/epoch130_exception0\")\n",
    "for i in tqdm(range(1000)):\n",
    "    make_step(trainer.model, data['batch'], trainer.opt_state, trainer.optim,\n",
    "              trainer.filter_spec, loss_name=\"mse\", max_grad_norm=None, l2_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4dcd7-9d86-4b5b-9334-b3bd2ff06494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tss-ml]",
   "language": "python",
   "name": "conda-env-.conda-tss-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
