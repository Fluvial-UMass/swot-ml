{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f020388-58f0-4da9-933a-6a02129cd624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import jax\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Force reload of project files\n",
    "import data, train, models, metrics\n",
    "importlib.reload(data)\n",
    "from data import DataLoader\n",
    "\n",
    "\n",
    "# Params\n",
    "features_dict = {'daily':['gage_Q'],\n",
    "                'irregular':['Blue','Green','Red','Nir','Swir1','Swir2']}\n",
    "target_label = 'tss'\n",
    "time_slice = slice('2008-01-01', '2023-12-31')\n",
    "split_time =  np.datetime64('2017-01-01')\n",
    "sequence_length = 90\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "data_dir = Path(\"../data/Sag\")\n",
    "\n",
    "dataloader = DataLoader(data_dir = data_dir,\n",
    "                        basins = ['sag_daily_data','sag_daily_data_2'],\n",
    "                        features_dict = features_dict,\n",
    "                        target = target_label,\n",
    "                        time_slice = time_slice,\n",
    "                        split_time = split_time,\n",
    "                        batch_size = batch_size, \n",
    "                        sequence_length = sequence_length,\n",
    "                        discharge_col = 'gage_Q',\n",
    "                        range_norm_cols = ['gage_Q','tss'])\n",
    "                        # log_norm_cols = ['gage_Q','tss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9e66e-0054-4dab-8dc5-0c6434c17fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea6b9fa682d40dca4ae5ac3a2c0f06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(models)\n",
    "importlib.reload(train)\n",
    "from models import TAPLSTM\n",
    "from train import make_step, lr_dict_scheduler\n",
    "\n",
    "lr_schedule = { \n",
    "    0: 0.005,\n",
    "    30: 0.001}\n",
    "\n",
    "# Initialize the model\n",
    "key = jax.random.PRNGKey(0)\n",
    "model = TAPLSTM(daily_in_size=len(features_dict['daily']),\n",
    "                irregular_in_size=len(features_dict['irregular']),\n",
    "                static_in_size=dataloader.x_s['sag_daily_data'].shape[0],\n",
    "                out_size=output_size, \n",
    "                hidden_size=hidden_size, \n",
    "                key=key)\n",
    "\n",
    "# Initialize optimizer \n",
    "current_lr = lr_dict_scheduler(0, lr_schedule)\n",
    "optim = optax.adam(current_lr)\n",
    "opt_state = optim.init(model)\n",
    "\n",
    "# Training loop\n",
    "loss_list = []\n",
    "pbar = trange(num_epochs, desc=\"Epoch\")\n",
    "for epoch in pbar:\n",
    "    # Update learning rate and optimizer\n",
    "    current_lr = lr_dict_scheduler(epoch, lr_schedule)\n",
    "    optim = optax.adam(current_lr)\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    dataloader.train = True\n",
    "    for _, _, batch in dataloader:\n",
    "        loss, model, opt_state = make_step(model, batch, opt_state, optim,\n",
    "                                           loss_name=\"mse\",\n",
    "                                           max_grad_norm=3,\n",
    "                                           l2_weight = 1E-5)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "            \n",
    "    current_loss = total_loss / num_batches\n",
    "    loss_list.append(current_loss)\n",
    "    pbar.set_postfix_str(f\"Loss: {current_loss:.4f}\")\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a574b-555e-4b6d-b0ac-575ccfd801f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def predict(model, batch):\n",
    "    return jax.vmap(model)(batch)\n",
    "\n",
    "basins = []\n",
    "dates = []\n",
    "y_hat = []\n",
    "# Predict on the test data\n",
    "dataloader.train = False\n",
    "for basin, date, batch in tqdm(dataloader):\n",
    "    basins.extend(basin)\n",
    "    dates.extend(date)\n",
    "    y_hat.extend(predict(model,batch))\n",
    "\n",
    "# Create a multi-index\n",
    "multi_index = pd.MultiIndex.from_arrays([basins,dates],names=['basin','date'])\n",
    "y_hat = np.array(y_hat).flatten()\n",
    "\n",
    "# Create a DataFrame with the multi-index\n",
    "predictions = pd.DataFrame({target_label: y_hat}, index=multi_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1eedf-9d1f-4b14-8d95-681be21343ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the true values and predictions\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "predictions.unstack(level='basin').plot(ax=ax1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f944086-a425-45cf-9a23-ca6c4262a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
