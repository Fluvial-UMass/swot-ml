{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abca3e8-e7be-4dc4-adfa-89647c86802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is required to run multiple processes on Unity for some reason.\n",
    "from multiprocessing import set_start_method\n",
    "set_start_method('spawn', force=True)\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_enable_command_buffer='\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.7'\n",
    "# os.environ['JAX_PLATFORMS'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f5da32-b4cb-4f70-8bb6-46fe21f28cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "src = str(Path('../src').resolve())\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)\n",
    "import config, data, models, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0071c1b9-f9f9-47c5-b802-71bd272a4446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model state from ../runs/flexible_hybrid_clip/base_config_20240827_220358/epoch050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 13:36:44.822402: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version (12.6.20). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model contains 178,755 parameters, using 698.26KB memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_kandread_umass_edu/tss-ml/src/data.py:256: UserWarning: Dropping numerical attributes with 0 variance or NaN values: ['glc_pc_s17', 'wet_pc_s07', 'glc_pc_s08', 'glc_pc_s05', 'glc_pc_s03', 'pnv_pc_s03', 'wet_pc_s06', 'wet_pc_s05', 'glc_pc_s19', 'glc_pc_s07']\n",
      "  warnings.warn(f\"Dropping numerical attributes with 0 variance or NaN values: {cols_to_drop}\", UserWarning)\n",
      "/work/pi_kandread_umass_edu/tss-ml/src/data.py:257: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  numerical_df.drop(columns=cols_to_drop, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Hash: a81acb9a40087e870fb9bba647932600844d18a66d7df956c53f3c9f7c95140d\n",
      "Using cached basin dataset file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c489d1ccaa04a7cbe424cf64c78c081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating Indices:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_dir = Path(\"../runs/flexible_hybrid_clip/base_config_20240827_220358\")\n",
    "cfg, model, trainer_state, opt_state, _ = train.load_last_state(run_dir)\n",
    "\n",
    "cfg['quiet'] = False\n",
    "cfg['data_subset'] = 'test'\n",
    "dataset = data.TAPDataset(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e66fbb-dc27-436f-a43c-88805520867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['batch_size'] = 1\n",
    "dataloader = data.TAPDataLoader(cfg, dataset)\n",
    "\n",
    "for basin, date, batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72461419-6327-4146-b15d-d3b138a9f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 365, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c43daea-ac55-4638-8a9a-d2ed689bc500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dynamic': {'era5': Array([[[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]]], dtype=float32),\n",
       "  'landsat': Array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)},\n",
       " 'static': Array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
       " 'y': Array([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]], dtype=float32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.tree.map(jnp.zeros_like, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3fec817-8036-40a4-a2be-8e90eb5ff13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2897733/3075629776.py:74: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  x_baseline = jax.tree_map(jnp.zeros_like, batch)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 78\u001b[0m\n\u001b[1;32m     74\u001b[0m x_baseline \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_map(jnp\u001b[38;5;241m.\u001b[39mzeros_like, batch)\n\u001b[1;32m     76\u001b[0m target_neuron_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y: y[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Assuming you want to focus on the first output\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m ig \u001b[38;5;241m=\u001b[39m \u001b[43mintegrated_gradients_flexiblehybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_baseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_neuron_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# # Print results\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# print(\"TSOI for each sample:\", tsoi_results)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print(\"Average TSOI:\", jnp.mean(tsoi_results))\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# print(\"Max TSOI:\", jnp.max(tsoi_results))\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# print(\"Min TSOI:\", jnp.min(tsoi_results))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m, in \u001b[0;36mintegrated_gradients_flexiblehybrid\u001b[0;34m(model, x, x_baseline, target_neuron_fn, steps)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target_neuron_fn(y)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate gradients along the path\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Average the gradients\u001b[39;00m\n\u001b[1;32m     33\u001b[0m avg_grads \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp\u001b[38;5;241m.\u001b[39mmean(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), grads)\n",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m, in \u001b[0;36mintegrated_gradients_flexiblehybrid.<locals>.grad_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_fn\u001b[39m(x):\n\u001b[1;32m     25\u001b[0m     key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Use a fixed key for deterministic behavior\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target_neuron_fn(y)\n",
      "File \u001b[0;32m/work/pi_kandread_umass_edu/tss-ml/src/models/flexible_hybrid.py:53\u001b[0m, in \u001b[0;36mFlexibleHybrid.__call__\u001b[0;34m(self, data, key)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Static embedding\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_embedder:\n\u001b[0;32m---> 53\u001b[0m     static_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_embedder(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, keys[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     static_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "\n",
    "def integrated_gradients_flexiblehybrid(model, x, x_baseline, target_neuron_fn, steps=100):\n",
    "    # Ensure model is in eval mode\n",
    "    model = eqx.nn.inference_mode(model)\n",
    "\n",
    "    # Create a path from baseline to input\n",
    "    def interpolate(alpha):\n",
    "        return {\n",
    "            'dynamic': {\n",
    "                k: x_baseline['dynamic'][k] + alpha * (x['dynamic'][k] - x_baseline['dynamic'][k])\n",
    "                for k in x['dynamic']\n",
    "            },\n",
    "            'static': x_baseline['static'] + alpha * (x['static'] - x_baseline['static'])\n",
    "            if 'static' in x else None\n",
    "        }\n",
    "\n",
    "    alphas = jnp.linspace(0, 1, steps)\n",
    "    path = [interpolate(alpha) for alpha in alphas]\n",
    "\n",
    "    # Define the gradient function\n",
    "    def grad_fn(x):\n",
    "        key = jax.random.PRNGKey(0)  # Use a fixed key for deterministic behavior\n",
    "        y = model(x, key)\n",
    "        return target_neuron_fn(y)\n",
    "\n",
    "    # Calculate gradients along the path\n",
    "    grads = jax.vmap(jax.grad(grad_fn))(path)\n",
    "\n",
    "    # Average the gradients\n",
    "    avg_grads = jax.tree_map(lambda x: jnp.mean(x, axis=0), grads)\n",
    "\n",
    "    # Calculate integrated gradients\n",
    "    integrated_grads = jax.tree_map(lambda g, x_b, x: g * (x - x_b), avg_grads, x_baseline, x)\n",
    "\n",
    "    return integrated_grads\n",
    "\n",
    "# def calculate_tsoi(ig, threshold=2e-3):\n",
    "#     # Sum integrated gradients across features and variables for each time step\n",
    "#     ig_sum = sum(jnp.sum(jnp.abs(ig['dynamic'][k]), axis=(1, 2)) for k in ig['dynamic'])\n",
    "    \n",
    "#     # Calculate differences between consecutive time steps\n",
    "#     differences = jnp.abs(jnp.diff(ig_sum))\n",
    "    \n",
    "#     # Find the first time step where the difference exceeds the threshold\n",
    "#     mask = differences > threshold\n",
    "#     if jnp.any(mask):\n",
    "#         first_significant_step = jnp.argmax(mask)\n",
    "#     else:\n",
    "#         first_significant_step = len(ig_sum) - 1\n",
    "    \n",
    "#     # Calculate TSOI\n",
    "#     tsoi = len(ig_sum) - first_significant_step\n",
    "    \n",
    "#     return tsoi\n",
    "\n",
    "def analyze_test_period(model, test_data, target_neuron_fn, threshold=2e-3):\n",
    "    tsoi_results = []\n",
    "    \n",
    "    for sample in test_data:\n",
    "        x = sample\n",
    "        x_baseline = jax.tree_map(jnp.zeros_like, x)\n",
    "        \n",
    "        ig = integrated_gradients_flexiblehybrid(model, x, x_baseline, target_neuron_fn)\n",
    "        tsoi = calculate_tsoi(ig, threshold)\n",
    "        tsoi_results.append(tsoi)\n",
    "    \n",
    "    return tsoi_results\n",
    "\n",
    "\n",
    "x = batch\n",
    "x_baseline = jax.tree.map(jnp.zeros_like, batch)\n",
    "\n",
    "target_neuron_fn = lambda y: y[0]  # Assuming you want to focus on the first output\n",
    "\n",
    "ig = integrated_gradients_flexiblehybrid(model, x, x_baseline, target_neuron_fn)\n",
    "\n",
    "\n",
    "# # Print results\n",
    "# print(\"TSOI for each sample:\", tsoi_results)\n",
    "# print(\"Average TSOI:\", jnp.mean(tsoi_results))\n",
    "# print(\"Max TSOI:\", jnp.max(tsoi_results))\n",
    "# print(\"Min TSOI:\", jnp.min(tsoi_results))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tss-ml]",
   "language": "python",
   "name": "conda-env-.conda-tss-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
